{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "TODO: In this cell, describe your choices for each of the following\n",
    "\n",
    "* PEFT technique: Lora\n",
    "* Model: \"bert-base-uncased\"\n",
    "* Evaluation approach: Accuracy and F1 score\n",
    "* Fine-tuning dataset: Glue, mrpc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f551c63a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "                   Trainer, AutoTokenizer, DataCollatorWithPadding, \n",
    "                   TrainingArguments, AutoModelForSequenceClassification,\n",
    "                   pipeline)\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import torch\n",
    "\n",
    "from peft import (\n",
    "    get_peft_config,\n",
    "    get_peft_model,\n",
    "    get_peft_model_state_dict,\n",
    "    set_peft_model_state_dict,\n",
    "    LoraConfig,\n",
    "    PeftType,\n",
    "    PrefixTuningConfig,\n",
    "    PromptEncoderConfig,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4935cb4d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "746d1d1108084a609ff6bae2d4e5099a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3668 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a55e090091e4cbfb12659a61fc8d77e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "491d2f4d29d44995b054c77f135e5f84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1725 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use the Glue dataset, mrpc subtask\n",
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
    "#\n",
    "# use a fully trained model in HF\n",
    "#\n",
    "model_name = \"Intel/bert-base-uncased-mrpc\"\n",
    "#\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f28c4a78",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 3668\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "019b9f55",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setup the model\n",
    "model_intel = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3970fadc-6ae3-4e59-a974-dd2c00b6e81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c29bfc7-5481-4dad-ac0a-c4fb3413c7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir=\"./results\",  # Specify a directory to store results\n",
    "                            per_device_eval_batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30f873d7-2fe9-4bd4-9863-a22bd0030028",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_intel = Trainer(model_intel,\n",
    "                     training_args,\n",
    "                     data_collator=data_collator,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70eead32-625d-43cd-bc67-bf0050b110e8",
   "metadata": {},
   "source": [
    "### reproduce the result published on https://huggingface.co/Intel/bert-base-uncased-mrpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d525879-557c-42a8-b22d-ca362194e812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(408, 2) (408,)\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer_intel.predict(tokenized_datasets[\"validation\"])\n",
    "print(predictions.predictions.shape, predictions.label_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9fad1d0-bb0e-46a2-95ee-921c654764c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8602941176470589, 'f1': 0.9042016806722689}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.argmax(predictions.predictions, axis=-1)\n",
    "metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "metric.compute(predictions=preds, references=predictions.label_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae074117-0ba5-4814-ad6b-31dbb74ffb4b",
   "metadata": {},
   "source": [
    "### since we will be using the validation dataset for fineturning, we will do the evaluation on the test dataset and compare with the result from finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e587068-020c-430b-b267-d37212e91ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1725, 2) (1725,)\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer_intel.predict(tokenized_datasets[\"test\"])\n",
    "print(predictions.predictions.shape, predictions.label_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9675a3d1-7f98-4cb6-8d9b-112d4372cdc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8307246376811595, 'f1': 0.87943848059455}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.argmax(predictions.predictions, axis=-1)\n",
    "metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "metric.compute(predictions=preds, references=predictions.label_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5775fadf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "peft_type = PeftType.LORA\n",
    "peft_config = LoraConfig(task_type=\"SEQ_CLS\", inference_mode=False, r=8, lora_alpha=16, lora_dropout=0.1)\n",
    "checkpoint = \"bert-base-uncased\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4d4c908",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 296,450 || all params: 109,780,228 || trainable%: 0.2700395193203643\n"
     ]
    }
   ],
   "source": [
    "lora_model = AutoModelForSequenceClassification.from_pretrained(checkpoint, return_dict=True)\n",
    "lora_model = get_peft_model(model, peft_config)\n",
    "lora_model.print_trainable_parameters()\n",
    "#lora_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2da21119-603b-4082-a0d4-0401c9ed4839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up training parameters\n",
    "training_args = TrainingArguments(\n",
    "            output_dir=\"./LoRA-Glue-mrpc.output\",\n",
    "            learning_rate=5e-4,\n",
    "            per_device_train_batch_size=16,\n",
    "            per_device_eval_batch_size=16,\n",
    "            num_train_epochs=10,\n",
    "            warmup_ratio=0.06,\n",
    "            weight_decay=0.01,\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            load_best_model_at_end=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b47abf88",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer_lora = Trainer(\n",
    "    lora_model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa7fe003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2300' max='2300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2300/2300 04:16, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.733951</td>\n",
       "      <td>0.857843</td>\n",
       "      <td>0.902357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.738344</td>\n",
       "      <td>0.855392</td>\n",
       "      <td>0.902801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.059700</td>\n",
       "      <td>0.693567</td>\n",
       "      <td>0.848039</td>\n",
       "      <td>0.892361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.059700</td>\n",
       "      <td>0.793152</td>\n",
       "      <td>0.848039</td>\n",
       "      <td>0.892361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.057200</td>\n",
       "      <td>0.744543</td>\n",
       "      <td>0.860294</td>\n",
       "      <td>0.903553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.057200</td>\n",
       "      <td>0.833532</td>\n",
       "      <td>0.862745</td>\n",
       "      <td>0.905085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.893501</td>\n",
       "      <td>0.857843</td>\n",
       "      <td>0.901695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.892675</td>\n",
       "      <td>0.850490</td>\n",
       "      <td>0.895009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.924186</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.898649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.918278</td>\n",
       "      <td>0.860294</td>\n",
       "      <td>0.903879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2300, training_loss=0.03770075010216754, metrics={'train_runtime': 257.1334, 'train_samples_per_second': 142.65, 'train_steps_per_second': 8.945, 'total_flos': 1439172244592160.0, 'train_loss': 0.03770075010216754, 'epoch': 10.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_lora.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99af4338-e936-46d2-a445-3592819fa474",
   "metadata": {},
   "source": [
    "### save the LoRA trained model locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8799e63f-1a51-4b35-86a8-02ea30cacfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_lora.save_model(\"./trained_lora_bert-base-uncased_glue_mrpc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "863ec66e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1725, 2) (1725,)\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer_lora.predict(tokenized_datasets[\"test\"])\n",
    "print(predictions.predictions.shape, predictions.label_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc3a8147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8359420289855073, 'f1': 0.8784886217260627}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.argmax(predictions.predictions, axis=-1)\n",
    "metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "metric.compute(predictions=preds, references=predictions.label_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13432f75-e70d-4821-9f8f-18bacfa1a1be",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### restore the model from local storage and see if we will get the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd9ec1a9-dc6f-469e-8fd4-f10c7b7d9c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LR = AutoModelForSequenceClassification.from_pretrained(\"./trained_lora_bert-base-uncased_glue_mrpc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0602e700-8f76-4fcf-9a5e-833c66670f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir=\"./results\",  # Specify a directory to store results\n",
    "                            per_device_eval_batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce118fa6-57d2-4c93-a7af-51dfa549aba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_LR = Trainer(model_LR,  \n",
    "                     training_args,\n",
    "                     data_collator=data_collator,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f8b47ca-0a8e-4cc8-9eb0-b9e6eaf0bd01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1725, 2) (1725,)\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer_LR.predict(tokenized_datasets[\"test\"])\n",
    "print(predictions.predictions.shape, predictions.label_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "afbbac55-67a3-49e1-95fa-882b619a93de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8359420289855073, 'f1': 0.8784886217260627}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.argmax(predictions.predictions, axis=-1)\n",
    "metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "metric.compute(predictions=preds, references=predictions.label_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5379f13-efaf-43fb-afdc-7d53074652fa",
   "metadata": {},
   "source": [
    "### Great! results are identical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e56167-26f8-4abf-8d2f-7f337ff33875",
   "metadata": {},
   "source": [
    "## Performing probing for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54db168e-b0ae-48a5-a21a-7cfedf289a89",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=2, bias=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
    "# freeze the base model, train the head only\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1779b013-88b7-40fa-9b14-6f5371a7eb73",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set up training parameters\n",
    "training_args = TrainingArguments(\n",
    "            output_dir=\"./Probe-Glue-mrpc.output\",\n",
    "            learning_rate=5e-4,\n",
    "            per_device_train_batch_size=16,\n",
    "            per_device_eval_batch_size=16,\n",
    "            num_train_epochs=10,\n",
    "            warmup_ratio=0.06,\n",
    "            weight_decay=0.01,\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            load_best_model_at_end=True,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b28785bd-a962-4485-9529-cf0aa56f3d6b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c88ca452-2556-488d-b07c-a1b93ca7747f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2300' max='2300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2300/2300 01:45, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.681864</td>\n",
       "      <td>0.678922</td>\n",
       "      <td>0.784893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.649563</td>\n",
       "      <td>0.683824</td>\n",
       "      <td>0.812227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.651500</td>\n",
       "      <td>0.627742</td>\n",
       "      <td>0.683824</td>\n",
       "      <td>0.812227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.651500</td>\n",
       "      <td>0.610396</td>\n",
       "      <td>0.681373</td>\n",
       "      <td>0.810496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.633700</td>\n",
       "      <td>0.634219</td>\n",
       "      <td>0.674020</td>\n",
       "      <td>0.798179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.633700</td>\n",
       "      <td>0.607365</td>\n",
       "      <td>0.681373</td>\n",
       "      <td>0.809942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.627500</td>\n",
       "      <td>0.607152</td>\n",
       "      <td>0.681373</td>\n",
       "      <td>0.810496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.627500</td>\n",
       "      <td>0.609143</td>\n",
       "      <td>0.681373</td>\n",
       "      <td>0.810496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.619200</td>\n",
       "      <td>0.604499</td>\n",
       "      <td>0.683824</td>\n",
       "      <td>0.811127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.619200</td>\n",
       "      <td>0.605775</td>\n",
       "      <td>0.681373</td>\n",
       "      <td>0.810496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2300, training_loss=0.6309705385954484, metrics={'train_runtime': 105.5653, 'train_samples_per_second': 347.463, 'train_steps_per_second': 21.787, 'total_flos': 1434208084991760.0, 'train_loss': 0.6309705385954484, 'epoch': 10.0})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d896ddb2-c896-4a1d-b896-00c7cd4f2a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1725, 2) (1725,)\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(tokenized_datasets[\"test\"])\n",
    "print(predictions.predictions.shape, predictions.label_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a7c18a67-6bf9-4abb-8a55-416933e1bcd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6660869565217391, 'f1': 0.7968970380818053}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.argmax(predictions.predictions, axis=-1)\n",
    "metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "metric.compute(predictions=preds, references=predictions.label_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a72439-ba06-492c-93d1-57b1667bb300",
   "metadata": {},
   "source": [
    "### perform fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d0ce9331-7b2a-4a89-be8c-84031f067d59",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=2, bias=True)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_FT = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
    "# freeze the base model, train the head only\n",
    "for param in model_FT.base_model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model_FT.classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d6e492be-967f-44eb-95e5-4af1c1ab5619",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set up training parameters\n",
    "training_args = TrainingArguments(\n",
    "            output_dir=\"./Finetuning-Glue-mrpc.output\",\n",
    "            learning_rate=2e-5,\n",
    "            per_device_train_batch_size=32,\n",
    "            per_device_eval_batch_size=32,\n",
    "            num_train_epochs=10,\n",
    "            warmup_ratio=0.06,\n",
    "            weight_decay=0.01,\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            load_best_model_at_end=True,\n",
    "            #resume_from_checkpoint=\"./Glue-mrpc.output/checkpoint-4600\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5e345781-fa9f-406f-9b90-734d321be449",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer_finetuning = Trainer(\n",
    "    model_FT,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b69e2274-39d2-4b0a-9ea1-8513ccfde0ea",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1150' max='1150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1150/1150 06:55, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.402041</td>\n",
       "      <td>0.848039</td>\n",
       "      <td>0.894558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.389491</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.875912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.544623</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.898649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.568398</td>\n",
       "      <td>0.848039</td>\n",
       "      <td>0.892361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.188500</td>\n",
       "      <td>0.687088</td>\n",
       "      <td>0.855392</td>\n",
       "      <td>0.899830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.188500</td>\n",
       "      <td>0.761946</td>\n",
       "      <td>0.840686</td>\n",
       "      <td>0.885362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.188500</td>\n",
       "      <td>0.778205</td>\n",
       "      <td>0.848039</td>\n",
       "      <td>0.893471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.188500</td>\n",
       "      <td>0.812998</td>\n",
       "      <td>0.845588</td>\n",
       "      <td>0.893761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.825476</td>\n",
       "      <td>0.848039</td>\n",
       "      <td>0.893836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.890116</td>\n",
       "      <td>0.850490</td>\n",
       "      <td>0.897479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1150, training_loss=0.0942319102909254, metrics={'train_runtime': 415.5293, 'train_samples_per_second': 88.273, 'train_steps_per_second': 2.768, 'total_flos': 1607678437123680.0, 'train_loss': 0.0942319102909254, 'epoch': 10.0})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_finetuning.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8300e4b1-4152-49d6-8e33-1837a694d8c3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1725, 2) (1725,)\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer_finetuning.predict(tokenized_datasets[\"test\"])\n",
    "print(predictions.predictions.shape, predictions.label_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aa90d048-ba08-4210-9250-f7a177ecbb3f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.808695652173913, 'f1': 0.8493150684931506}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.argmax(predictions.predictions, axis=-1)\n",
    "metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "metric.compute(predictions=preds, references=predictions.label_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8fb014-a09d-4a5b-8faa-60996b5e0b81",
   "metadata": {},
   "source": [
    "Below is a summary of results for different apprroaches, \"Intel\" is the optimally fine tuned model by Intel available in Hugging Face hub; \"Probe\" is the result from tuning only the head classifier; \"LoRA\" is for LoRA PEFT and \"FT\" is obtained from fine tuning the entire model.\n",
    "\n",
    "\"LoRA\" achieved the same level of accuracy as fine tuning, but at 62% of the computational cost.\n",
    "\n",
    "| Model | Accuracy | F1 Score | Timing (secs) |\n",
    "|:---|---|:---:|---:|\n",
    "| Intel | 0.83 | 0.88 | < 1 |\n",
    "| Probe | 0.67 | 0.80 | 106 |\n",
    "| LoRA | 0.83 | 0.88 | 257 |\n",
    "| FT | 0.81 | 0.85 | 415 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbd9cfb-1286-4fb2-b9c5-667bc8d44581",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
